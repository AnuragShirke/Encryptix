## IMPORTING DEPENDENCIES
import pandas as pd
import numpy as np
df=pd.read_csv(r"C:\Users\anura\OneDrive\Desktop\Encryptix\Customer Churn\Churn_Modelling.csv")
df.head()
df.shape
df.describe(include="all")
## DATA PREPROCESSING
df.notnull().sum()
df.duplicated().sum()
df['Exited'].value_counts() #0 = not churn 1=churn
df['Geography'].value_counts()
df.drop(df.columns[[0,1,2]],axis=1,inplace=True)
df.head()
df.shape
df=pd.get_dummies(df,columns=['Geography','Gender'],drop_first=True,dtype=int)
x=df.drop(columns=['Exited'])
y=df['Exited']
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=1)
x_train.shape
from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()    #mean=0 and std=1
x_train_scaled=scaler.fit_transform(x_train)
x_test_scaled=scaler.fit_transform(x_test)
x_train_scaled
## USING DIFFERENT CLASSIFIERS
### 1.LOGISTIC REGRESSION
from sklearn.linear_model import LogisticRegression
LR = LogisticRegression(solver='liblinear')
LR.fit(x_train_scaled, y_train)
predictions=LR.predict(x_test_scaled)
from sklearn.metrics import accuracy_score
LR_Accuracy_Score = accuracy_score(y_test, predictions)
print(LR_Accuracy_Score)
### 2.RANDOM FOREST
from sklearn.ensemble import RandomForestClassifier
RF=RandomForestClassifier()
RF.fit(x_train_scaled,y_train)
predictions2=RF.predict(x_test_scaled)
RF_accuracy=accuracy_score(y_test,predictions2)
print(RF_accuracy)
### 3.GRADIENT BOOSTING
from sklearn.ensemble import GradientBoostingClassifier
gb_reg = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)
gb_reg.fit(x_train_scaled, y_train)
predictions3=gb_reg.predict(x_test_scaled)
gb_accuracy=accuracy_score(y_test,predictions3)
print(gb_accuracy)
